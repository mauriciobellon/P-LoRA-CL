# Anexos

## Anexo A: Código-fonte principal

O código-fonte está organizado em `src/plora_cl/` com os seguintes módulos:

- **`cli/`**: Interface de linha de comando
  - `train.py`: Comando de treinamento
  - `visualize.py`: Geração de gráficos e tabelas
- **`models/`**: Arquiteturas e componentes
  - `base_model.py`: Modelo base com cabeças por tarefa
  - `lora_adapters.py`: Gerenciamento de adaptadores LoRA
  - `orthogonal_lora.py`: O-LoRA com restrições ortogonais
  - `ewc.py`: Elastic Weight Consolidation
- **`training/`**: Loop de treinamento
  - `trainer.py`: Treinador sequencial principal
  - `baselines.py`: Implementações de baselines
  - `loss.py`: Funções de perda compostas
  - `replay.py`: Geração de replay sintético
- **`data/`**: Carregamento de dados
  - `datasets.py`: Configurações de tarefas (AG News, Yelp, Amazon, DBPedia, Yahoo)
  - `preprocessing.py`: Tokenização e preparação
- **`evaluation/`**: Métricas e tracking
  - `metrics.py`: ACC, BWT, FWT, Forgetting
  - `tracker.py`: Salvamento de resultados

## Anexo B: Configurações de Experimentos

As configurações são armazenadas em arquivos YAML (exemplo em `experiments/config.yaml.example`):

```yaml
model_name: "distilbert-base-uncased"
device: "auto"  # ou "cpu", "cuda"
seed: 42

# Treinamento
batch_size: 32
learning_rate: 1e-4
epochs: 3

# LoRA
lora_r: 8
lora_alpha: 16

# Regularização
lambda_ortho: 0.1
lambda_ewc: 100.0
replay_ratio: 0.2

# Componentes
use_ewc: true
use_orthogonal: true
use_replay: true
use_lateral: false
```

## Anexo C: Execução de Experimentos

**Comando básico:**
```bash
uv run python -m plora_cl.cli.train --experiment-name baseline
```

**Com arquivo de configuração:**
```bash
uv run python -m plora_cl.cli.train --config experiments/meu_experimento/config.yaml
```

**Visualização de resultados:**
```bash
uv run python -m plora_cl.cli.visualize \
  --experiment-name baseline \
  --output-dir plots/
```

## Anexo D: Estrutura de Resultados

Os experimentos salvam automaticamente em `experiments/<nome>/`:

- **`config.json`**: Configuração completa do experimento
- **`logs/`**: Logs de treinamento por época
- **`results/`**: Métricas finais (ACC, BWT, FWT, Forgetting)
- **`checkpoints/`**: Estados dos adaptadores por tarefa (opcional)
