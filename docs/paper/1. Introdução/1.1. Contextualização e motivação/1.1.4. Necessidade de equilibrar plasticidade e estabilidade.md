# 1.1.4. Necessidade de equilibrar plasticidade e estabilidade

O desafio central do aprendizado contínuo pode ser entendido como o dilema estabilidade-plasticidade (Grossberg, 1987): um modelo deve ser suficientemente plástico para incorporar novos conhecimentos, mas suficientemente estável para preservar conhecimentos anteriores. Maximizar apenas a plasticidade leva ao esquecimento catastrófico, enquanto maximizar apenas a estabilidade impede o aprendizado de novas tarefas.

A solução ideal requer um equilíbrio dinâmico entre esses dois objetivos, permitindo que o modelo adapte-se seletivamente a novas distribuições enquanto protege parâmetros críticos para tarefas anteriores. Esse equilíbrio é particularmente desafiador em PLN, onde diferentes tarefas podem compartilhar conhecimento linguístico fundamental (beneficiando-se de transferência positiva) ou podem conflitar em suas representações (requerendo isolamento). Abordagens complementares têm sido propostas: arquiteturas que isolam atualizações (Progressive Neural Networks; Rusu et al., 2016), regularização baseada em informação (Elastic Weight Consolidation; Kirkpatrick et al., 2017) e mecanismos de replay (incluindo replay gerativo; Shin et al., 2017), além de métodos de adaptação parametricamente eficientes como adapters e LoRA (Houlsby et al., 2019; Hu et al., 2021).
