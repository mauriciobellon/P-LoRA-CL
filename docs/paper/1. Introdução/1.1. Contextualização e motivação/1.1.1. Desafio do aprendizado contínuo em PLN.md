# 1.1.1. Desafio do aprendizado contínuo em PLN

O aprendizado contínuo em Processamento de Linguagem Natural (PLN) representa um desafio fundamental para sistemas de inteligência artificial que precisam operar em ambientes dinâmicos. Em aplicações reais, modelos de linguagem enfrentam sequências de tarefas heterogêneas: desde classificação de sentimento em avaliações de produtos até perguntas e respostas sobre documentação técnica, passando por análise de intenções em sistemas de atendimento. Cada nova tarefa ou domínio requer adaptação do modelo, mas a capacidade de incorporar novos conhecimentos sem degradar o desempenho em tarefas anteriormente aprendidas permanece um problema em aberto.

Diferentemente do fine-tuning tradicional, onde um modelo é ajustado uma vez sobre um conjunto fixo de dados, o aprendizado contínuo implica treinar modelos sequencialmente em múltiplas tarefas ou distribuições que chegam ao longo do tempo. Essa natureza sequencial é natural em muitos contextos: assistentes virtuais que precisam aprender novos comandos sem esquecer funcionalidades antigas, sistemas de monitoramento que devem se adaptar a novas fontes de dados, ou aplicações educacionais que incorporam progressivamente novos tópicos curriculares.

Em tais cenários, a literatura reporta que atualizações para novas tarefas frequentemente interferem com parâmetros críticos de tarefas anteriores, produzindo degradações substanciais na ausência de mecanismos de proteção (McCloskey & Cohen, 1989; French, 1999). Esse fenômeno motiva o desenvolvimento de abordagens de aprendizado contínuo que combinem isolamento estrutural, regularização informativa e replay, especialmente em arquiteturas Transformer amplamente utilizadas em PLN.