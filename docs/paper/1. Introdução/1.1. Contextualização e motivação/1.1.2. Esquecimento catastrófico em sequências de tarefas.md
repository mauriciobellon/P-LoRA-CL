# 1.1.2. Esquecimento catastrófico em sequências de tarefas

O principal obstáculo ao aprendizado contínuo eficaz é o fenômeno do esquecimento catastrófico, documentado desde os primórdios das redes neurais (McCloskey & Cohen, 1989; French, 1999). Quando um modelo neural é treinado sequencialmente em tarefas diferentes, os gradientes da tarefa atual tendem a sobrescrever parâmetros críticos para tarefas anteriores, levando a uma degradação abrupta do desempenho em tarefas antigas. Esse efeito é particularmente pronunciado em arquiteturas modernas de Transformers, onde milhões de parâmetros são compartilhados entre diferentes camadas e a interferência entre tarefas pode ocorrer em múltiplos níveis de representação.

Em PLN, o esquecimento catastrófico se manifesta de forma especialmente problemática devido à natureza contextual e ambígua da linguagem natural. Um modelo que aprendeu a classificar sentimento em avaliações de restaurantes pode perder completamente essa capacidade ao ser ajustado para responder perguntas sobre notícias, mesmo que ambas as tarefas compartilhem conhecimento linguístico fundamental. Esse comportamento contrasta com o aprendizado humano, onde novos conhecimentos são integrados de forma mais gradual e seletiva, preservando habilidades anteriores.
