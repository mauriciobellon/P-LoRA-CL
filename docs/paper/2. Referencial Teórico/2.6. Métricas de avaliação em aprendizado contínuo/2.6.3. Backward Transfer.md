# 2.6.3. Backward Transfer

O Backward Transfer mede formalmente o efeito do aprendizado de novas tarefas sobre o desempenho em tarefas anteriores. Lopez-Paz e Ranzato (2017) definem BWT como:

BWT = (1/(N-1)) Σ_{i=1}^{N-1} (R_{N,i} - R_{i,i})

onde R_{i,i} é a acurácia obtida imediatamente após treinar a tarefa i (pico) e R_{N,i} é a acurácia na tarefa i após treinar todas as N tarefas. Se BWT for negativo, indica esquecimento em média (transferência "para trás" negativa); se for positivo, indica que o modelo melhorou em tarefas antigas depois de aprender novas (transferência para trás positiva). Técnicas bem-sucedidas buscam tornar BWT o mais próximo de 0 possível (idealmente positivo).

Em arranjos híbridos, observar BWT próximo de 0 ao lado de ACC alto sugere bom equilíbrio estabilidade-plasticidade. BWT positivo pode ocorrer quando tarefas futuras melhoram representações úteis às passadas (e.g., pré-treino adicional implícito via replay), enquanto BWT muito negativo indica conflitos severos e pode motivar ampliar isolamento (mais capacidade LoRA, ortogonalidade mais forte) ou reforço (replay mais frequente).
