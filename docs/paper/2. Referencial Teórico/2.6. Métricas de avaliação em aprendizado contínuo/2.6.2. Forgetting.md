# 2.6.2. Forgetting

A métrica de esquecimento foca explicitamente na perda de desempenho que o modelo sofreu em tarefas antigas após aprender novas tarefas. Uma forma comum de defini-la é comparar, para cada tarefa j, a melhor acurácia que o modelo obteve em j em algum ponto do treinamento com a acurácia em j ao final do treinamento de todas as tarefas. Se A_j^max foi a acurácia da tarefa j logo que o modelo terminou de aprender T_j e A_j^final é a acurácia em j após a tarefa final T_N, podemos definir a taxa de esquecimento em j como F_j = A_j^max - A_j^final.

A métrica permite quantificar rigorosamente o impacto destrutivo do aprendizado sequencial e é essencial para validar técnicas cujo objetivo é minimizar esse efeito. Valores positivos indicam esquecimento catastrófico (pior quanto maior), e valores negativos (teoricamente possíveis) indicariam que o modelo melhorou em tarefas antigas mesmo após aprender novas.

Agregados úteis incluem a média de F_j ao longo das tarefas e a distribuição de F_j (picos de esquecimento em poucas tarefas podem indicar conflitos específicos). Em cenários de PLN com tarefas heterogêneas, reportar forgetting por tipo de tarefa (classificação vs geração) ajuda a revelar onde cada mecanismo (EWC, replay, LoRA) é mais eficaz.
