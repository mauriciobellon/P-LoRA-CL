# 2.6.5. Custo paramétrico e computacional

Além das métricas de desempenho, avalia-se também o custo em recursos de cada estratégia. Uma métrica comum é acompanhar o número de parâmetros adicionais que o modelo adquire por tarefa (model size growth). Idealmente, deseja-se que a eficiência de memória seja alta — o modelo não deve crescer muito conforme N aumenta. Por exemplo, PNNs teriam um crescimento linear pesado (100% por tarefa), enquanto LoRA pode crescer <1% por tarefa; EWC não cresce nada em parâmetros do modelo (0%), mas requer armazenar algumas estatísticas por peso.

Avalia-se também a eficiência computacional — frequentemente medida em tempo de treinamento (ou FLOPs) adicional introduzido pelas técnicas de CL. Métodos com replay (real ou gerativo) praticamente dobram o número de amostras processadas por iteração, enquanto regularizações como EWC têm overhead mínimo no tempo de treino. Para uma avaliação abrangente, não basta verificar se o modelo mantém alta acurácia em todas as tarefas; é preciso também verificar quanto custo de memória e computação foi pago para alcançar aquele resultado.
