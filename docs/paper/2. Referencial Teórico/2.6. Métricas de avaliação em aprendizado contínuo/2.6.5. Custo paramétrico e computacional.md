# 2.6.5. Custo paramétrico e computacional

Além das métricas de desempenho, avalia-se também o custo em recursos de cada estratégia. Uma métrica comum é acompanhar o número de parâmetros adicionais que o modelo adquire por tarefa (model size growth). Idealmente, deseja-se que a eficiência de memória seja alta — o modelo não deve crescer muito conforme N aumenta. Por exemplo, PNNs teriam um crescimento linear pesado (100% por tarefa), enquanto LoRA pode crescer <1% por tarefa; EWC não cresce nada em parâmetros do modelo (0%), mas requer armazenar algumas estatísticas por peso.

Avalia-se também a eficiência computacional — frequentemente medida em tempo de treinamento (ou FLOPs) adicional introduzido pelas técnicas de CL. Métodos com replay (real ou gerativo) praticamente dobram o número de amostras processadas por iteração, enquanto regularizações como EWC têm overhead mínimo no tempo de treino. Para uma avaliação abrangente, não basta verificar se o modelo mantém alta acurácia em todas as tarefas; é preciso também verificar quanto custo de memória e computação foi pago para alcançar aquele resultado.

Para relatórios transparentes, recomenda-se explicitar: (i) parâmetros adicionais por tarefa (e cumulativos); (ii) footprint em memória/VRAM na inferência (com e sem merge de adapters); (iii) tempo total de treinamento (ou FLOPs) por tarefa e por sequência; e (iv) custos de geração no replay (tokens gerados/segundo). Em combinações como QLoRA+LoRA, o backbone quantizado reduz VRAM, enquanto adapters em precisão maior garantem plasticidade com custo marginal.
