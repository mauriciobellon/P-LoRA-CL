# 2.5.5. Vantagens e limitações

O replay gerativo evita a necessidade de armazenar dados originais, contornando problemas de privacidade e economizando espaço. Um gerador eficaz pode potencialmente produzir uma diversidade maior de exemplos do que um buffer limitado, enriquecendo o treinamento e levando a melhor generalização. Métodos de replay gerativo têm demonstrado sucesso em recuperar desempenho em tarefas antigas quase no nível de métodos com buffer real, quando conseguem gerar amostras fiéis.

As limitações incluem a dependência crítica da qualidade e do balanceamento dos exemplos gerados. Há um risco conhecido de degradação cumulativa: se o modelo principal começa a esquecer uma tarefa, suas gerações daquela tarefa também pioram, criando um ciclo vicioso ("efeito catastrófico circular"). Outra limitação é o custo computacional: gerar dados não é gratuito — frequentemente, para cada minibatch de dados reais, o modelo precisa gerar um número de exemplos antigos, aumentando proporcionalmente o tempo de treinamento.

Mitigações incluem: (i) congelar parcialmente o gerador (ou usar um gerador dedicado) para estabilizar as distribuições sintéticas; (ii) curar prompts e condicionamentos; (iii) usar verificação externa de qualidade (um classificador/avaliador fixo); e (iv) combinar replay com regularização/isolamento paramétrico para reduzir a dependência exclusiva de dados gerados. Em ambientes restritos (privacidade/latência), a combinação de LoRA por tarefa com replay esparso e EWC leve tende a oferecer um bom compromisso entre custo, privacidade e estabilidade.
