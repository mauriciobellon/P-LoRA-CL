# 2.2.2. Isolamento de parâmetros por tarefa

A característica fundamental das PNNs é o isolamento completo entre tarefas em termos de parâmetros. Cada coluna atende a uma tarefa específica, garantindo que uma tarefa nova não degrade o desempenho das anteriores através de interferência destrutiva direta. Como os parâmetros das colunas antigas não são modificados, a PNN elimina o esquecimento catastrófico por construção — o aprendizado de T_k não interfere diretamente nos pesos que foram sintonizados para tarefas anteriores.

Esse isolamento é conceitualmente simples e teoricamente garantido, mas vem ao custo de crescimento linear do número de parâmetros em função do número de tarefas. Para cada nova tarefa adiciona-se uma coluna completa de rede, o que pode se tornar impraticável quando as tarefas são numerosas ou quando a arquitetura base é muito grande.

Na inferência, PNNs típicas assumem conhecimento do ID da tarefa para rotear entradas para a coluna apropriada (task-aware). Em cenários task-agnostic, estratégias de roteamento ou detecção (por exemplo, um seletor leve treinado sobre representações compartilhadas) tornam-se necessárias. Alternativas como Progress & Compress (Schwarz et al., 2018) tentam reduzir o custo ao distilar/compactar conhecimento de colunas antigas em uma base compartilhada, mantendo um buffer (ou regularização) que previne regressão em tarefas passadas.
