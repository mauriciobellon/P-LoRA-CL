# 2.1.4. Contexto específico do PLN

Em PLN, o aprendizado contínuo apresenta desafios adicionais e motivação especial. Enquanto em visão computacional ou robótica as tarefas podem ser bem delimitadas (por exemplo, diferentes conjuntos de classes de imagens), em PLN há grande diversidade de tarefas: classificação de intenção, análise de sentimento, perguntas e respostas, tradução, sumarização, entre outras. Essas tarefas frequentemente envolvem dados textuais de domínios distintos e objetivos variáveis.

A linguagem natural é inerentemente ambígua e dependente do contexto, com vocabulário em constante evolução. Essa natureza dinâmica reforça a motivação para sistemas de PLN que aprendam continuamente: aplicações reais frequentemente precisam incorporar novas gírias, tópicos emergentes, mudanças de estilo ou domínio linguístico sem perder a habilidade em tarefas anteriores. Um assistente virtual pode precisar aprender progressivamente novos tipos de consultas dos usuários ao longo do tempo, sem esquecer como responder às solicitações antigas.

Além da diversidade de objetivos, o ecossistema de PLN traz particularidades: (i) tarefas podem ser multi-rótulo, multi-turno e sensíveis a contexto, exigindo memória de longo prazo; (ii) mudanças de domínio podem alterar distribuições lexicais e pragmáticas, exigindo adaptação rápida sem “descalibrar” competências gerais; (iii) restrições de privacidade e confidencialidade dificultam rehearsal com dados brutos, motivando replay gerativo (Sun et al., 2020) ou métodos puramente paramétricos.

Outro ponto é a diferença entre regimes multi-tarefa e contínuo. Em multi-tarefa, o otimizador vê exemplos de todas as tarefas simultaneamente, o que facilita chegar a regiões de solução compatíveis. Em contínuo, o fluxo é sequencial, e o caminho de otimização importa: trajetórias podem atravessar “gargalos” em que atualizações para a tarefa atual movem o modelo para fora da região de bom desempenho para tarefas antigas. Por isso, estratégias de proteção (EWC/MAS/SI), isolamento (PNN, subespaços LoRA por tarefa) e reforço (replay real/gerativo) são centrais no contexto de PLN.
