# 2.1.3. Esquecimento catastrófico em redes neurais

O esquecimento catastrófico ocorre quando o treinamento em uma nova tarefa altera parâmetros que eram críticos para tarefas anteriores. Em redes neurais profundas, onde milhões de parâmetros são compartilhados entre diferentes camadas e funções, essa interferência pode ocorrer em múltiplos níveis. O problema é especialmente pronunciado quando tarefas novas e antigas requerem atualizações conflitantes dos mesmos parâmetros.

A natureza do esquecimento catastrófico em Transformers é particularmente complexa devido à arquitetura de atenção e às múltiplas camadas de representação. Parâmetros compartilhados em embeddings, camadas de atenção e redes feed-forward podem ser afetados de forma diferente dependendo de como as tarefas utilizam essas representações. Compreender e mitigar essas interferências requer abordagens que identifiquem e protejam parâmetros críticos ou que isolam atualizações para diferentes tarefas.

Entre os mecanismos de mitigação, destacam-se: (i) isolamento estrutural via PNNs (Rusu et al., 2016); (ii) regularização baseada em informação via EWC (Kirkpatrick et al., 2017; Schwarz et al., 2018); (iii) replay (Shin et al., 2017), inclusive sem dados brutos; e (iv) restrições ortogonais sobre atualizações/espelhos de parâmetros (Zeng et al., 2019; Farajtabar et al., 2019).

Uma forma operacional de diagnosticar esquecimento é acompanhar a curva R_{i,j}: o desempenho em j após treinar i tarefas (Lopez-Paz & Ranzato, 2017). Quedas consistentes de R_{i,j} quando i aumenta são indicativas de interferência destrutiva. Adicionalmente, inspeções de similaridade de gradientes entre tarefas e de normas de atualização por camada fornecem evidências de onde e como a degradação ocorre. Em Transformers, esquecimentos podem concentrar-se em projeções de atenção (Q/K/V/O) ou em projeções internas do MLP, a depender do tipo de tarefa e do padrão de reutilização de representações.

Em modelos de linguagem generativos, há o risco adicional de “ciclo catastrófico”: ao começar a esquecer uma tarefa anterior, o próprio gerador degrada a qualidade das amostras dessa tarefa em métodos de replay gerativo, o que retroalimenta o esquecimento. Técnicas como regularização leve nas camadas base (EWC/MAS/SI), buffers curados (GEM/A-GEM) ou alocação de subespaços de adaptação com baixa sobreposição (p. ex., LoRA com ortogonalidade) atenuam esse ciclo, mantendo sinais de gradiente úteis para tarefas pretéritas.
