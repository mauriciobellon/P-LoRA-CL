# 2.4.4. Consolidação de conhecimento crítico

Pesos críticos ficam quase "congelados" (alta penalização se mudarem), enquanto pesos pouco relevantes podem se ajustar livremente à nova tarefa. Dessa forma, o EWC tenta obter um compromisso ótimo entre não esquecer o passado e ainda aprender o novo, encontrando uma região no espaço de parâmetros que minimize a perda da tarefa atual sem sair da região de bom desempenho das tarefas antigas.

A consolidação é particularmente efetiva quando aplicada a componentes compartilhados que mantêm conhecimento linguístico fundamental, como embeddings ou camadas iniciais do modelo. Essas camadas frequentemente codificam conhecimento geral que beneficia múltiplas tarefas, tornando-as candidatas ideais para proteção via EWC.
