# 2.4.1. Regularização baseada em importância de pesos

Elastic Weight Consolidation (EWC), proposto por Kirkpatrick et al. (2017), é um método de regularização que busca preservar o conhecimento prévio dentro dos mesmos parâmetros ao longo de tarefas sequenciais. A premissa é adicionar um termo de penalização na função de perda durante o treinamento de novas tarefas, desencorajando grandes mudanças nos pesos que foram identificados como importantes para tarefas antigas.

Antes de aprender a tarefa T_k, o algoritmo EWC calcula, para cada peso θ_j do modelo, um valor de importância que quantifica o quanto θ_j contribuiu para o desempenho nas tarefas anteriores. Essa importância é tipicamente estimada através da matriz de informação de Fisher, avaliada nos dados das tarefas passadas. Intuitivamente, se um peso influenciava fortemente as predições corretas nas tarefas antigas, o EWC irá puni-lo caso ele se desvie muito do seu valor original enquanto aprende a nova tarefa.
