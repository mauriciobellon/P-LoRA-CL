# 2.4.1. Regularização baseada em importância de pesos

Elastic Weight Consolidation (EWC), proposto por Kirkpatrick et al. (2017), é um método de regularização que busca preservar o conhecimento prévio dentro dos mesmos parâmetros ao longo de tarefas sequenciais. A premissa é adicionar um termo de penalização na função de perda durante o treinamento de novas tarefas, desencorajando grandes mudanças nos pesos que foram identificados como importantes para tarefas antigas.

Antes de aprender a tarefa T_k, o algoritmo EWC calcula, para cada peso θ_j do modelo, um valor de importância que quantifica o quanto θ_j contribuiu para o desempenho nas tarefas anteriores. Essa importância é tipicamente estimada através da matriz de informação de Fisher, avaliada nos dados das tarefas passadas. Intuitivamente, se um peso influenciava fortemente as predições corretas nas tarefas antigas, o EWC irá puni-lo caso ele se desvie muito do seu valor original enquanto aprende a nova tarefa.

Métodos afins incluem MAS (Memory Aware Synapses; Aljundi et al., 2018) e SI (Synaptic Intelligence; Zenke et al., 2017), que estimam importâncias por sensibilidade das saídas ou trajetórias de otimização. Essas variantes diferem no procedimento de estimação e podem ser mais robustas quando dados passados não estão disponíveis integralmente. Em PLN, aplicar regularização leve nas camadas compartilhadas (embeddings e blocos inferiores) preserva competências gerais, enquanto camadas superiores e adapters (e.g., LoRA) mantêm plasticidade para especialização.
