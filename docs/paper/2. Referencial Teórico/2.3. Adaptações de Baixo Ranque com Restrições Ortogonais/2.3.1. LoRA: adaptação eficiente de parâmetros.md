# 2.3.1. LoRA: adaptação eficiente de parâmetros

O LoRA (Low-Rank Adaptation), proposto por Hu et al. (2021), oferece uma forma de adaptar modelos de linguagem de grande porte de maneira leve e modular. A técnica funciona congelando todos os pesos originais do modelo pré-treinado e injetando pequenos módulos treináveis de baixo ranque em cada camada relevante da arquitetura Transformer.

Para cada matriz de pesos W em camadas selecionadas (por exemplo, nas projeções de atenção ou na rede feed-forward), LoRA introduz duas matrizes menores A e B de dimensões de posto r (tipicamente r bem menor que o tamanho original da camada) de forma que a atualização da camada seja W + ΔW, onde ΔW = AB representa um ajuste de baixo ranque aprendido para a nova tarefa. Em vez de ajustar todos os pesos do modelo, apenas os parâmetros nesses pequenos módulos são aprendidos.
