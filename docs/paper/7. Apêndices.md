# Apêndices

## Apêndice A: Configurações completas de hiperparâmetros

Exemplo (valores de referência; ajustar por tarefa):
- Otimizador: `AdamW` (β1=0,9; β2=0,999; weight_decay=0,01)
- Taxa de aprendizado base (LoRA): 1e-4 (varrer {5e-5, 1e-4, 2e-4})
- Warmup: 5% dos passos
- Batch size efetivo: 64 (com acúmulo de gradiente)
- Comprimento máximo de sequência: {256, 384, 512} por dataset
- LoRA: r∈{4,8}, α=16, dropout=0,05, alvos={Q,K,V,O} (ou MLP)
- Ortogonalidade (λ_ortho): {0,01; 0,05; 0,1}
- EWC (λ_ewc): {10; 50; 100}, Fisher diagonal, amostras=2k
- Replay gerativo: proporção do batch {0,1; 0,2; 0,3}, temperatura {0,7; 0,9}

## Apêndice B: Pseudocódigo dos algoritmos principais

Algoritmo 1 — Treinamento sequencial com O-LoRA, EWC e replay gerativo
1. para k = 1..K (tarefas)
2.   inicializar adaptadores LoRA para T_k (ΔW=0)
3.   congelar adaptadores de T_1..T_{k-1}
4.   se k>1: estimar lote(s) sintéticos S via gerador (prompts por classe)
5.   para cada batch B de T_k: formar B' = mix(B, S, p_replay)
6.     L = L_ce(B') + λ_ortho·R_ortho(ΔW_k, {ΔW_i}_{i<k}) + λ_ewc·R_ewc(θ)
7.     atualizar {ΔW_k} e pesos destravados com otimizador
8.   estimar Fisher em T_k para EWC
9.   avaliar em T_1..T_k (ACC, BWT, FWT, Forgetting)

## Apêndice C: Tabelas detalhadas de resultados por tarefa

Sugerido (exemplo de colunas):
- Tarefa | ACC@t | Best@t | Forgetting | BWT | FWT | Parâmetros (+%) | Tempo (min) | Pico VRAM (GB)

## Apêndice D: Análise adicional de ablação

Plano de ablações:
- Sem O-LoRA (LoRA padrão)
- Sem EWC (λ_ewc=0)
- Sem replay gerativo (p_replay=0)
- Sem conexões laterais
- Apenas O-LoRA; Apenas EWC; Apenas replay
- Variação de r (LoRA) e λ_ortho

## Apêndice E: Instruções de reprodução dos experimentos

### Pré-requisitos
- Python 3.11 com `uv` instalado
- CPU (funcional) ou GPU com 16GB VRAM (recomendado)

### Instalação

```bash
# Instalar ambiente
./install

# Ou manualmente:
uv python install 3.11
uv venv
uv pip install -e .

# Com dependências de desenvolvimento:
uv pip install -e ".[dev]"
```

### Formatação e lint

```bash
uv run ruff format src tests
uv run ruff check src tests
```

### Testes

```bash
# Testes rápidos
uv run pytest tests -q

# Com coverage
uv run pytest --cov=plora_cl tests
```

### Execução de Experimentos

**Baseline completo:**
```bash
uv run python -m plora_cl.cli.train --experiment-name baseline
```

**Com configuração customizada:**
```bash
uv run python -m plora_cl.cli.train \
  --config experiments/meu_experimento/config.yaml \
  --experiment-name meu_experimento
```

**Ablação (exemplo - sem O-LoRA):**
```bash
uv run python -m plora_cl.cli.train \
  --experiment-name ablation_no_olora \
  --use-orthogonal false
```

### Visualização

```bash
uv run python -m plora_cl.cli.visualize \
  --experiment-name baseline \
  --output-dir plots/baseline/
```

### Protocolos
- Registrar seeds (via `--seed`), commits git e versões de bibliotecas
- Resultados salvos automaticamente em `experiments/<nome>/results/`
- Métricas (ACC, BWT, FWT, Forgetting) calculadas após cada tarefa
- Checkpoints grandes: considerar armazenamento externo (config via flag)
