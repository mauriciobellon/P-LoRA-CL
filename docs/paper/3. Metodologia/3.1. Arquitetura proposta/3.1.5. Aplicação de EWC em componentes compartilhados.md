# 3.1.5. Aplicação de EWC em componentes compartilhados

O EWC é aplicado seletivamente apenas aos componentes compartilhados que permanecem treináveis durante o aprendizado contínuo. Notadamente, aplicamos EWC aos embeddings do modelo base e, potencialmente, a algumas camadas iniciais que são parcialmente destravadas para permitir ajustes finos de conhecimento linguístico fundamental.

Após o treinamento em cada tarefa T_i, estimamos a matriz de informação de Fisher sobre os dados de T_i para identificar quais pesos são críticos para o desempenho nessa tarefa. Nas tarefas subsequentes, incorporamos um termo de penalização EWC na função de perda que desencoraja grandes mudanças nesses pesos críticos, preservando conhecimento fundamental enquanto permite ajustes necessários para novas tarefas.

Adotamos a aproximação diagonal de Fisher e a variante Online EWC (Schwarz et al., 2018) com fator de decaimento para evitar acúmulo excessivo de rigidez ao longo de longas sequências. Em prática, amostramos um subconjunto estratificado de exemplos por tarefa para estimar Fisher (p. ex., 5k–20k exemplos, conforme disponibilidade), garantindo custo controlado. O termo EWC é aplicado apenas aos pesos parcialmente destravados; adaptadores LoRA permanecem livres, fornecendo o canal principal de plasticidade.
