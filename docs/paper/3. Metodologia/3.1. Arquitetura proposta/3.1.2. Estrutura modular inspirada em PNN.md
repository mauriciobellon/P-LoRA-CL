# 3.1.2. Estrutura modular inspirada em PNN

A arquitetura incorpora princípios de modularização progressiva inspirados em PNN (Rusu et al., 2016), mas de forma parametricamente eficiente. Em vez de adicionar colunas completas de rede para cada tarefa, adicionamos apenas conjuntos de adaptadores LoRA leves. Cada tarefa recebe seu próprio conjunto de adaptadores que são congelados após o treinamento dessa tarefa, criando isolamento estrutural similar ao das PNNs, mas com crescimento paramétrico muito menor.

A estrutura modular permite que adaptadores de tarefas anteriores sejam mantidos em memória e ativados durante a inferência conforme necessário. Essa abordagem mantém a propriedade de isolamento completa das PNNs (adaptadores anteriores não são atualizados durante treinamento de novas tarefas) enquanto reduz drasticamente o custo de armazenamento e computação.
