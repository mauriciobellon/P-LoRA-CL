# 3.4.1. Framework e bibliotecas

A implementação utiliza PyTorch como framework principal de deep learning, aproveitando sua flexibilidade para implementar componentes customizados. HuggingFace Transformers fornece modelos base pré-treinados e utilitários de tokenização, enquanto PEFT (Parameter-Efficient Fine-Tuning) oferece implementações otimizadas de LoRA e gerenciamento de adaptadores.

Avalanche (ContinualAI) é utilizado para o protocolo de aprendizado contínuo, gerenciamento de sequências de tarefas, e implementação de EWC. O framework também fornece utilitários para avaliação cumulativa e cálculo de métricas padronizadas de CL. Componentes customizados são desenvolvidos para integração de O-LoRA, replay gerativo, e conexões laterais.

Versões e reprodutibilidade: utilizamos versões estáveis de PyTorch e Transformers (Wolf et al., 2020), e a biblioteca Avalanche (Lomonaco et al., 2021). Fixamos seeds de PyTorch/NumPy/Python e habilitamos, quando viável, flags determinísticas. Scripts de execução registram hashes de commit e versões de dependências para reprodutibilidade.
