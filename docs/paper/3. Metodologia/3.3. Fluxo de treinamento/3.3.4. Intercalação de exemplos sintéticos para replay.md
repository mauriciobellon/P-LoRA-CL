# 3.3.4. Intercalação de exemplos sintéticos para replay

Antes de cada época de treinamento na tarefa atual T_k, geramos um conjunto balanceado de exemplos sintéticos representando as tarefas anteriores T_1, ..., T_{k-1}. A geração é guiada por prompts estruturados que especificam a tarefa e a classe desejada, e os exemplos são gerados utilizando o modelo configurado para geração de texto.

Os exemplos sintéticos são intercalados com os dados reais da tarefa atual durante o treinamento, compondo tipicamente 10-30% de cada batch. Essa proporção é um hiperparâmetro que pode ser ajustado, mas valores muito altos podem reduzir a plasticidade para a tarefa atual, enquanto valores muito baixos podem não fornecer reforço suficiente para tarefas anteriores.

Políticas de amostragem: (i) uniformemente entre tarefas anteriores; (ii) proporcional ao esquecimento estimado por tarefa (maior quota para tarefas com maior queda de desempenho); (iii) foco em classes minoritárias para evitar viés. Mantemos um orçamento fixo de tokens gerados por tarefa/época para controlar custo. Gerações são cacheadas e invalidadas ao alternar de tarefa.
