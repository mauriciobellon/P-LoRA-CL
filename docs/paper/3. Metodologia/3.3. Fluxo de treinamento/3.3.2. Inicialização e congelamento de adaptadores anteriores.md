# 3.3.2. Inicialização e congelamento de adaptadores anteriores

Novos adaptadores LoRA são inicializados seguindo a prática padrão: matrizes A são inicializadas aleatoriamente (distribuição normal pequena) e matrizes B são inicializadas com zeros, garantindo que ΔW = 0 inicialmente e o modelo começa com o comportamento do modelo base para a nova tarefa.

Adaptadores de tarefas anteriores são completamente congelados — seus parâmetros não são atualizados durante o treinamento da tarefa atual. Isso garante isolamento estrutural e previne interferência destrutiva. Os adaptadores congelados permanecem em memória e podem ser ativados durante a inferência quando necessário para a tarefa correspondente.
