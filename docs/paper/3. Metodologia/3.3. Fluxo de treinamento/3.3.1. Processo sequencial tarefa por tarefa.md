# 3.3.1. Processo sequencial tarefa por tarefa

O treinamento segue um protocolo estritamente sequencial: cada tarefa é treinada completamente antes de iniciar a próxima. Não há acesso a dados futuros durante o treinamento de uma tarefa atual, simulando um cenário realista onde tarefas chegam uma de cada vez ao longo do tempo.

Para cada tarefa T_k na sequência:
1. Avaliamos o modelo em todas as tarefas anteriores (T_1, ..., T_{k-1}) para medir desempenho atual antes de iniciar T_k
2. Inicializamos novos adaptadores LoRA para T_k
3. Congelamos adaptadores de tarefas anteriores (T_1, ..., T_{k-1})
4. Treinamos os novos adaptadores sobre T_k com perda composta (incluindo termos de ortogonalidade e EWC)
5. Intercalamos exemplos sintéticos de tarefas anteriores durante o treinamento
6. Após convergência, estimamos matriz de Fisher para EWC nas tarefas futuras
7. Avaliamos o modelo em todas as tarefas vistas até então (T_1, ..., T_k)

Agendamento de treino: utilizamos otimizador AdamW com scheduler linear com warmup (p. ex., 6–10% dos steps totais) e early stopping por métrica de validação da tarefa corrente. O número de épocas por tarefa é limitado (p. ex., 3–5) para manter custo controlado; em datasets grandes, usamos orçamento de steps fixo por tarefa. Durante toda a sequência, mantemos seeds fixas e registramos R_{i,j} após cada tarefa para cálculo de métricas agregadas (3.5.4).
