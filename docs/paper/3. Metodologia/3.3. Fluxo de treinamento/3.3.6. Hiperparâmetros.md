# 3.3.6. Hiperparâmetros

Seguimos diretrizes conservadoras para calibração de hiperparâmetros baseadas em práticas estabelecidas na literatura. Utilizamos AdamW como otimizador com taxa de aprendizado na faixa de 1e-4 a 3e-4 para adaptadores LoRA, e weight decay até 0,01. Ranks LoRA são configurados entre 4 e 8, com alpha conforme prática do PEFT (tipicamente alpha = rank ou 2*rank).

Para o EWC, o hiperparâmetro λ é calibrado através de busca em conjunto de validação, tipicamente variando entre 100 e 10000 dependendo da escala dos valores de Fisher. Para ortogonalidade, o hiperparâmetro λ_ortho é tipicamente configurado entre 0,1 e 1,0, balanceando isolamento com plasticidade.

Parâmetros de decodificação para replay gerativo (temperature, top-p) são ajustados por tarefa para garantir qualidade das gerações, e early stopping é aplicado com base na métrica de validação corrente para evitar overfitting.

Scheduler de LR: linear com warmup de 6–10% dos steps; gradiente clipping (p. ex., 1.0) para estabilidade; batch efetivo obtido via acúmulo de gradiente. Dropout de LoRA 0.0–0.1 conforme validação. Em setups com QLoRA, seguimos as configurações recomendadas (Dettmers et al., 2023) para quantização e escalonamento do LR. As buscas de hiperparâmetros são restritas e compartilhadas entre métodos comparados, para evitar viés.
